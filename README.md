**Select** a Language: [English](#en) - [Português](#pt)




# <a name="en"> [Final Paper] Power Quality Disturbances Classification with Machine Learning </a>

Final paper: "[TCC] Paulo Careli.pdf"

This is my final paper project for Electrical Engineering course at UFJF. This final paper focuses on generating and comparing machine learning models that are able to classify power quality disturbances. Signals containing 14 types of disturbances are going to be simulated, and, a dataset with those signals will be exported. With Python, a signal processing technique will be applied to the signals, followed by the extraction of 9 features of each one, creating a new dataset that will be used for classification. This new dataset is going to be used to train 8 different machine learning models. After that, they will be compared and evaluated.

Student: [Paulo H. P. Careli]

Advisor: [Leandro R. Manso Silva]

[Paulo H. P. Careli]: https://github.com/PauloCareli
[Leandro R. Manso Silva]: http://lattes.cnpq.br/1421239770201461


## <a name="projectorganization"> Project Organization </a>


    ├── README.md          <- README
    ├── data    
    │   ├── processed      <- The final dataset used.
    │   └── raw            <- The original dataset, generated by .m files.
    │
    ├── models             <- Trained and serialized models.
    │
    ├── notebooks          <- Codes to test the models.                         
    │
    ├── src                <- Source code used.
    │   │   
    │   ├── data           <- Scripts to generate dataset with the signals.
    │   │   └── Signals    <- Scripts used to create the signals.
    │   │
    │   ├── features       <- Scripts to extract the features from the previous generated dataset.
    │   │       
    │   └── models         <- Scripts to train models, make predictions and export the models.
    │     
    ├── requirements.txt   <- The requirements file generated with "pipreqs" for this project. Use "pip install -r requirements.txt" to install them.
    │     
    └── [TCC] Paulo Careli <- Final paper.

--------

## Installation

To run the .m files, you will need **MATLAB** or **OCTAVE**. You can also run those files in Python by using some extra packages, you still need one of them installed though.

To install all dependencies needed to run this project, first install **[Python]** and then **[Pip]** if it isn't installed yet. After that, run the line below with the terminal inside the root folder:

[Python]: https://www.python.org/downloads/
[Pip]: https://phoenixnap.com/kb/install-pip-windows

    pip install -r requirements.txt
    
You might have some **troubles** while trying to install the **stockwell** package. To install it, I recommend you to **follow** the guide from the [Stockwell] repository. **Linux** is a good choice to run this package, since it might be harder to install on Windows.



[Stockwell]: https://github.com/claudiodsf/stockwell.


## Usage

After installing everything, open the main folder with a text editor (I chose [Visual Studio Code]). 

[Visual Studio Code]: https://code.visualstudio.com/download

- Run "create_dataset.m" located inside _src_ > _data_ as showed in the [project organization](#projectorganization) section to create the dataset. A new dataset will be saved at _data_ > _raw_. The dataset used was too big for Github, so it was uploaded to Google Drive, follow the link in the .txt inside _data_ > _raw_ to download it.
- Run "extract_features.py" located inside _src_ > _features_ to extract the features and create the dataset that will be used for classfication. A new dataset will be saved at _data_ > _processed_.
- Choose the ML algorithm located inside _src_ > _models_ to create a model and see it's results. The models will be saved at _models_ (this project used all of them).
- Run "compare_models.py" located inside _notebooks_ to compare all models created (this code will try to compare all 8 of them at the moment).

## More about the Project

You can check more about of the project (all the details, references and results) in the final file _[TCC] Paulo Careli.pdf_ (only available in portuguese).


---


# <a name="pt"> [TCC] Classificação de Distúrbios de Qualidade de Energia com Machine Learning </a>

Trabalho de Conclusão de Curso: "[TCC] Paulo Careli.pdf"

Este é o meu TCC para o curso de Engenharia Elétrica na UFJF. Este trabalho de Conclusão de Curso tem como foco gerar e comparar modelos de aprendizado de máquina que sejam capazes de classificar distúrbios de qualidade de energia. Serão simulados sinais contendo 14 tipos de distúrbios, a fim de montar um conjunto de dados e exportá-lo. Utilizando Python, será feito um processamento dos sinais deste conjunto, seguido da extração de 9 características, montando assim, um novo conjunto de dados que será utilizado para a classificação. Este novo conjunto será utilizado para o treinamento de 8 modelos de aprendizado de máquina diferentes. Logo após, será feita a comparação e avaliação dos mesmos.

Estudante: [Paulo H. P. Careli]

Orientador: [Leandro R. Manso Silva]

[Paulo H. P. Careli]: https://github.com/PauloCareli
[Leandro R. Manso Silva]: http://lattes.cnpq.br/1421239770201461

## <a name="organizacaodoprojeto"> Organização do Projeto </a>


    ├── README.md          <- LEIAME
    ├── data    
    │   ├── processed      <- Conjunto de dados final utilizado.
    │   └── raw            <- Conjunto de dados original, gerado pelos arquivos .m.
    │
    ├── models             <- Modelos treinados e salvos.
    │
    ├── notebooks          <- Códigos para testar os modelos.                         
    │
    ├── src                <- Código fonte utilizado.
    │   │   
    │   ├── data           <- Código para gerar o conjunto de dados contendo os sinais.
    │   │   └── Signals    <- Códigos utilizados para criar os sinais.
    │   │
    │   ├── features       <- Códigos para extrair as características do conjunto de dados criado previamente.
    │   │       
    │   └── models         <- Códigos para treinar, fazer predições e exportar os modelos.
    │     
    ├── requirements.txt   <- Conjunto de requerimentos para este projeto gerado pelo "pipreqs". Use "pip install -r requirements.txt" para instalá-los.
    │     
    └── [TCC] Paulo Careli <- Trabalho de Conclusão de Curso.

--------

## Instalação

Para rodar os arquivos .m, será necessário ter o **MATLAB** ou o **OCTAVE** instalado em sua máquina. Você também pode rodar estes códigos em Python utilizando algumas bibliotecas extras, entretanto, ainda será necessário ter um dos dois instalado.

Para instalar todas as dependências necessárias para rodar este projeto, primeiro instale o **[Python]** e depois o **[Pip]** se estes ainda não estiverem instalados. Depois, rode o código abaixo no terminal aberto nas pasta raíz do projeto:

[Python]: https://www.python.org/downloads/
[Pip]: https://phoenixnap.com/kb/install-pip-windows

    pip install -r requirements.txt
    
Você pode encontrar alguns **problemas** enquanto tenta instalar a biblioteca **Stockwell**. Para instalá-la, eu recomendo que você **siga** o guia do repositório [Stockwell]. **Linux** é uma ótima escolha para rodar esta biblioteca, já que no windows pode ser um pouco mais difícil de executar a instalação.

[Stockwell]: https://github.com/claudiodsf/stockwell.


## Utilização

Depois de instalar tudo, abra a pasta principal com um editor de texto de sua preferência (eu escolhi o  [Visual Studio Code]).

[Visual Studio Code]: https://code.visualstudio.com/download

- Execute o código "create_dataset.m" localizado em _src_ > _data_ como mostrado na seção [organização do projeto](#organizacaodoprojeto) para criar o conjunto de dados. Um novo conjunto de dados irá ser salvo em _data_ > _raw_. O conjunto de dados utilizado era muito grande para o Github, então ele foi salvo no Google Drive, siga o link dentro do .txt localizado em _data_ > _raw_ para baixá-lo.
- Execute o código "extract_features.py" localizado em _src_ > _features_ para extrair as características e criar um novo conjunto de dados que será utilizado para a classificação. Um novo conjunto de dados será salvo em _data_ > _processed_.
- Escolha o algitmo de ML localizado em _src_ > _models_ para criar um modelo e ver seus resultados. Os modelos irão ser salvos em _models_ (este projeto utilizou todos os modelos).
- Execute o código "compare_models.py" localizado em _notebooks_ para comparar todos os modelos criados (este código irá tentar comparar todos os 8 modelos gerados previamente).

## Mais sobre o Projeto

Você pode ver mais sobre o Projeto (todos os detalhes, referências e resultados) no arquivo final _[TCC] Paulo Careli.pdf_.
